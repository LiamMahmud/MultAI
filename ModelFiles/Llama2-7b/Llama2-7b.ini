[MODEL CONFIG]
model_name = llama2-7b
context_window = 4096
chat_format = llama-2


