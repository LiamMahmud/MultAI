[MODEL CONFIG]
model_name = llama2-7b
context_window = 4096
chat_format = llama-2
number_layers = 33
model_size = 4.45
